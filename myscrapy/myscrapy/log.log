2019-12-29 15:30:14 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: myscrapy)
2019-12-29 15:30:14 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2019-12-29 15:30:14 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'myscrapy', 'LOG_FILE': './log.log', 'NEWSPIDER_MODULE': 'myscrapy.spiders', 'SPIDER_MODULES': ['myscrapy.spiders']}
2019-12-29 15:30:14 [scrapy.extensions.telnet] INFO: Telnet Password: d3f5bd3ce4508d24
2019-12-29 15:30:14 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-12-29 15:30:14 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-12-29 15:30:14 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-12-29 15:30:14 [scrapy.middleware] INFO: Enabled item pipelines:
['myscrapy.pipelines.MyscrapyPipeline']
2019-12-29 15:30:14 [scrapy.core.engine] INFO: Spider opened
2019-12-29 15:30:14 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-12-29 15:30:14 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-12-29 15:30:15 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
2019-12-29 15:30:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['13', '19', '28', '30', '33', '2', '12'], 'qishu': '19090 '}
2019-12-29 15:30:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['4', '13', '20', '26', '28', '3', '12'], 'qishu': '19091 '}
2019-12-29 15:30:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['2', '11', '15', '27', '30', '2', '5'], 'qishu': '19092 '}
2019-12-29 15:30:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['16', '17', '26', '29', '35', '1', '7'], 'qishu': '19093 '}
2019-12-29 15:30:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['1', '12', '14', '26', '27', '7', '9'], 'qishu': '19094 '}
2019-12-29 15:30:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['3', '12', '17', '19', '31', '2', '6'], 'qishu': '19095 '}
2019-12-29 15:30:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['2', '12', '22', '23', '27', '2', '6'], 'qishu': '19096 '}
2019-12-29 15:30:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['10', '17', '20', '30', '35', '10', '12'], 'qishu': '19097 '}
2019-12-29 15:30:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['13', '15', '17', '19', '22', '3', '4'], 'qishu': '19098 '}
2019-12-29 15:30:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['4', '6', '18', '27', '33', '7', '9'], 'qishu': '19099 '}
2019-12-29 15:30:15 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['5', '8', '12', '19', '21', '6', '11'], 'qishu': '19100 '}
2019-12-29 15:30:15 [scrapy.core.engine] INFO: Closing spider (finished)
2019-12-29 15:30:15 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 282,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7932,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.482734,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 12, 29, 7, 30, 15, 208035),
 'item_scraped_count': 11,
 'log_count/DEBUG': 12,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'start_time': datetime.datetime(2019, 12, 29, 7, 30, 14, 725301)}
2019-12-29 15:30:15 [scrapy.core.engine] INFO: Spider closed (finished)
2019-12-29 15:32:22 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: myscrapy)
2019-12-29 15:32:22 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2019-12-29 15:32:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'myscrapy', 'LOG_FILE': './log.log', 'NEWSPIDER_MODULE': 'myscrapy.spiders', 'SPIDER_MODULES': ['myscrapy.spiders']}
2019-12-29 15:32:22 [scrapy.extensions.telnet] INFO: Telnet Password: 9cd9e986c1930e75
2019-12-29 15:32:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-12-29 15:32:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-12-29 15:32:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-12-29 15:32:22 [scrapy.middleware] INFO: Enabled item pipelines:
['myscrapy.pipelines.MyscrapyPipeline']
2019-12-29 15:32:22 [scrapy.core.engine] INFO: Spider opened
2019-12-29 15:32:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-12-29 15:32:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-12-29 15:32:22 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['13', '19', '28', '30', '33', '2', '12'], 'qishu': '19090 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['4', '13', '20', '26', '28', '3', '12'], 'qishu': '19091 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['2', '11', '15', '27', '30', '2', '5'], 'qishu': '19092 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['16', '17', '26', '29', '35', '1', '7'], 'qishu': '19093 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['1', '12', '14', '26', '27', '7', '9'], 'qishu': '19094 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['3', '12', '17', '19', '31', '2', '6'], 'qishu': '19095 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['2', '12', '22', '23', '27', '2', '6'], 'qishu': '19096 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['10', '17', '20', '30', '35', '10', '12'], 'qishu': '19097 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['13', '15', '17', '19', '22', '3', '4'], 'qishu': '19098 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['4', '6', '18', '27', '33', '7', '9'], 'qishu': '19099 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['5', '8', '12', '19', '21', '6', '11'], 'qishu': '19100 '}
2019-12-29 15:32:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111> (referer: http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100)
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['5', '11', '18', '19', '27', '5', '6'], 'qishu': '19101 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['5', '10', '15', '19', '31', '3', '6'], 'qishu': '19102 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['5', '12', '22', '27', '32', '4', '7'], 'qishu': '19103 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['2', '7', '19', '22', '28', '3', '5'], 'qishu': '19104 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['1', '4', '9', '14', '17', '1', '6'], 'qishu': '19105 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['5', '8', '10', '32', '35', '2', '10'], 'qishu': '19106 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['5', '9', '19', '27', '35', '2', '3'], 'qishu': '19107 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['24', '27', '28', '31', '34', '4', '8'], 'qishu': '19108 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['2', '7', '8', '20', '25', '11', '12'], 'qishu': '19109 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['1', '19', '23', '24', '30', '4', '5'], 'qishu': '19110 '}
2019-12-29 15:32:23 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['6', '15', '20', '23', '27', '8', '10'], 'qishu': '19111 '}
2019-12-29 15:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122> (referer: http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111)
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['3', '10', '16', '21', '33', '5', '6'], 'qishu': '19112 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['3', '11', '27', '34', '35', '1', '2'], 'qishu': '19113 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['3', '5', '7', '20', '23', '4', '11'], 'qishu': '19114 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['1', '18', '21', '28', '32', '5', '12'], 'qishu': '19115 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['2', '10', '16', '21', '23', '2', '12'], 'qishu': '19116 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['1', '18', '21', '25', '35', '7', '8'], 'qishu': '19117 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['2', '3', '13', '19', '26', '2', '3'], 'qishu': '19118 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['3', '6', '9', '23', '34', '2', '11'], 'qishu': '19119 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['6', '15', '17', '22', '25', '1', '9'], 'qishu': '19120 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['1', '2', '3', '7', '17', '4', '10'], 'qishu': '19121 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['5', '19', '25', '31', '33', '10', '11'], 'qishu': '19122 '}
2019-12-29 15:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133> (referer: http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122)
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['3', '13', '15', '26', '30', '5', '12'], 'qishu': '19123 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['7', '17', '26', '27', '30', '6', '12'], 'qishu': '19124 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['5', '8', '9', '14', '34', '2', '5'], 'qishu': '19125 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['5', '9', '16', '18', '30', '4', '7'], 'qishu': '19126 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['4', '7', '8', '11', '16', '9', '11'], 'qishu': '19127 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['20', '21', '25', '34', '35', '3', '12'], 'qishu': '19128 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['10', '13', '18', '23', '30', '6', '12'], 'qishu': '19129 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['1', '13', '20', '21', '26', '4', '10'], 'qishu': '19130 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['5', '6', '14', '27', '29', '6', '10'], 'qishu': '19131 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['3', '5', '6', '13', '18', '10', '12'], 'qishu': '19132 '}
2019-12-29 15:32:24 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['3', '12', '24', '27', '34', '1', '12'], 'qishu': '19133 '}
2019-12-29 15:32:24 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144> (referer: http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133)
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['5', '6', '7', '14', '17', '10', '11'], 'qishu': '19134 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['4', '5', '19', '25', '26', '1', '11'], 'qishu': '19135 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['3', '16', '20', '26', '29', '3', '9'], 'qishu': '19136 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['3', '5', '12', '13', '26', '7', '12'], 'qishu': '19137 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['4', '6', '7', '20', '29', '2', '4'], 'qishu': '19138 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['1', '5', '7', '8', '11', '6', '10'], 'qishu': '19139 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['3', '7', '8', '25', '27', '3', '5'], 'qishu': '19140 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['2', '10', '20', '21', '35', '1', '12'], 'qishu': '19141 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['3', '4', '26', '29', '33', '6', '7'], 'qishu': '19142 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['4', '22', '23', '24', '32', '6', '12'], 'qishu': '19143 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['2', '5', '20', '28', '31', '2', '11'], 'qishu': '19144 '}
2019-12-29 15:32:25 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155> (referer: http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144)
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['6', '15', '17', '22', '25', '1', '9'], 'qishu': '19120 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['1', '2', '3', '7', '17', '4', '10'], 'qishu': '19121 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['5', '19', '25', '31', '33', '10', '11'], 'qishu': '19122 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['3', '13', '15', '26', '30', '5', '12'], 'qishu': '19123 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['7', '17', '26', '27', '30', '6', '12'], 'qishu': '19124 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['5', '8', '9', '14', '34', '2', '5'], 'qishu': '19125 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['5', '9', '16', '18', '30', '4', '7'], 'qishu': '19126 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['4', '7', '8', '11', '16', '9', '11'], 'qishu': '19127 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['20', '21', '25', '34', '35', '3', '12'], 'qishu': '19128 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['10', '13', '18', '23', '30', '6', '12'], 'qishu': '19129 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['1', '13', '20', '21', '26', '4', '10'], 'qishu': '19130 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['5', '6', '14', '27', '29', '6', '10'], 'qishu': '19131 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['3', '5', '6', '13', '18', '10', '12'], 'qishu': '19132 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['3', '12', '24', '27', '34', '1', '12'], 'qishu': '19133 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['5', '6', '7', '14', '17', '10', '11'], 'qishu': '19134 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['4', '5', '19', '25', '26', '1', '11'], 'qishu': '19135 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['3', '16', '20', '26', '29', '3', '9'], 'qishu': '19136 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['3', '5', '12', '13', '26', '7', '12'], 'qishu': '19137 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['4', '6', '7', '20', '29', '2', '4'], 'qishu': '19138 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['1', '5', '7', '8', '11', '6', '10'], 'qishu': '19139 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['3', '7', '8', '25', '27', '3', '5'], 'qishu': '19140 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['2', '10', '20', '21', '35', '1', '12'], 'qishu': '19141 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['3', '4', '26', '29', '33', '6', '7'], 'qishu': '19142 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['4', '22', '23', '24', '32', '6', '12'], 'qishu': '19143 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['2', '5', '20', '28', '31', '2', '11'], 'qishu': '19144 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['5', '9', '19', '22', '32', '3', '5'], 'qishu': '19145 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['10', '11', '26', '33', '34', '1', '6'], 'qishu': '19146 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['9', '12', '19', '22', '33', '7', '8'], 'qishu': '19147 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['3', '4', '7', '11', '30', '8', '9'], 'qishu': '19148 '}
2019-12-29 15:32:25 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['1', '2', '7', '33', '35', '6', '10'], 'qishu': '19149 '}
2019-12-29 15:32:25 [scrapy.core.engine] INFO: Closing spider (finished)
2019-12-29 15:32:25 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2340,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 50869,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 3.301693,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 12, 29, 7, 32, 25, 635078),
 'item_scraped_count': 85,
 'log_count/DEBUG': 91,
 'log_count/INFO': 10,
 'request_depth_max': 5,
 'response_received_count': 6,
 'scheduler/dequeued': 6,
 'scheduler/dequeued/memory': 6,
 'scheduler/enqueued': 6,
 'scheduler/enqueued/memory': 6,
 'start_time': datetime.datetime(2019, 12, 29, 7, 32, 22, 333385)}
2019-12-29 15:32:25 [scrapy.core.engine] INFO: Spider closed (finished)
2019-12-29 15:42:05 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: myscrapy)
2019-12-29 15:42:05 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2019-12-29 15:42:05 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'myscrapy', 'LOG_FILE': './log.log', 'NEWSPIDER_MODULE': 'myscrapy.spiders', 'SPIDER_MODULES': ['myscrapy.spiders']}
2019-12-29 15:42:05 [scrapy.extensions.telnet] INFO: Telnet Password: bb26bac08e19b986
2019-12-29 15:42:05 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-12-29 15:42:06 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-12-29 15:42:06 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-12-29 15:42:06 [scrapy.middleware] INFO: Enabled item pipelines:
['myscrapy.pipelines.MyscrapyPipeline']
2019-12-29 15:42:06 [scrapy.core.engine] INFO: Spider opened
2019-12-29 15:42:06 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-12-29 15:42:06 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-12-29 15:42:06 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
2019-12-29 15:42:06 [scrapy.core.scraper] ERROR: Spider error processing <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
Traceback (most recent call last):
  File "d:\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\Workspace\WorkspaceForPython\SrcapyProject\myscrapy\myscrapy\spiders\sipder1.py", line 33, in parse
    item['qishu'] = qishu
  File "d:\python\python37\lib\site-packages\scrapy\item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'MyscrapyItem does not support field: qishu'
2019-12-29 15:42:06 [scrapy.core.engine] INFO: Closing spider (finished)
2019-12-29 15:42:06 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 282,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7932,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.573047,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 12, 29, 7, 42, 6, 710759),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2019, 12, 29, 7, 42, 6, 137712)}
2019-12-29 15:42:06 [scrapy.core.engine] INFO: Spider closed (finished)
2019-12-29 15:43:04 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: myscrapy)
2019-12-29 15:43:04 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2019-12-29 15:43:04 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'myscrapy', 'LOG_FILE': './log.log', 'NEWSPIDER_MODULE': 'myscrapy.spiders', 'SPIDER_MODULES': ['myscrapy.spiders']}
2019-12-29 15:43:04 [scrapy.extensions.telnet] INFO: Telnet Password: 04e9f87dbdd8ab60
2019-12-29 15:43:04 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-12-29 15:43:05 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-12-29 15:43:05 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-12-29 15:43:05 [scrapy.middleware] INFO: Enabled item pipelines:
['myscrapy.pipelines.MyscrapyPipeline']
2019-12-29 15:43:05 [scrapy.core.engine] INFO: Spider opened
2019-12-29 15:43:05 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-12-29 15:43:05 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-12-29 15:43:05 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
2019-12-29 15:43:05 [scrapy.core.scraper] ERROR: Spider error processing <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
Traceback (most recent call last):
  File "d:\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\Workspace\WorkspaceForPython\SrcapyProject\myscrapy\myscrapy\spiders\sipder1.py", line 33, in parse
    item['qishu'] = qishu
  File "d:\python\python37\lib\site-packages\scrapy\item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'MyscrapyItem does not support field: qishu'
2019-12-29 15:43:05 [scrapy.core.engine] INFO: Closing spider (finished)
2019-12-29 15:43:05 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 282,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7932,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.40345,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 12, 29, 7, 43, 5, 476495),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2019, 12, 29, 7, 43, 5, 73045)}
2019-12-29 15:43:05 [scrapy.core.engine] INFO: Spider closed (finished)
2019-12-29 22:54:22 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: myscrapy)
2019-12-29 22:54:22 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2019-12-29 22:54:22 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'myscrapy', 'LOG_FILE': './log.log', 'NEWSPIDER_MODULE': 'myscrapy.spiders', 'SPIDER_MODULES': ['myscrapy.spiders']}
2019-12-29 22:54:22 [scrapy.extensions.telnet] INFO: Telnet Password: 5adde8ac3f3b73ec
2019-12-29 22:54:22 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-12-29 22:54:22 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-12-29 22:54:22 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-12-29 22:54:22 [scrapy.middleware] INFO: Enabled item pipelines:
['myscrapy.pipelines.MyscrapyPipeline']
2019-12-29 22:54:22 [scrapy.core.engine] INFO: Spider opened
2019-12-29 22:54:22 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-12-29 22:54:22 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-12-29 22:54:23 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
2019-12-29 22:54:23 [scrapy.core.scraper] ERROR: Spider error processing <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
Traceback (most recent call last):
  File "d:\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\Workspace\WorkspaceForPython\SrcapyProject\myscrapy\myscrapy\spiders\sipder1.py", line 35, in parse
    item['nnn'] = 'nnn'
  File "d:\python\python37\lib\site-packages\scrapy\item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'MyscrapyItem does not support field: nnn'
2019-12-29 22:54:23 [scrapy.core.engine] INFO: Closing spider (finished)
2019-12-29 22:54:23 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 282,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7932,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.392119,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 12, 29, 14, 54, 23, 333292),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2019, 12, 29, 14, 54, 22, 941173)}
2019-12-29 22:54:23 [scrapy.core.engine] INFO: Spider closed (finished)
2019-12-29 22:55:46 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: myscrapy)
2019-12-29 22:55:46 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2019-12-29 22:55:46 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'myscrapy', 'LOG_FILE': './log.log', 'NEWSPIDER_MODULE': 'myscrapy.spiders', 'SPIDER_MODULES': ['myscrapy.spiders']}
2019-12-29 22:55:46 [scrapy.extensions.telnet] INFO: Telnet Password: 378289ba175f87c8
2019-12-29 22:55:46 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-12-29 22:55:46 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-12-29 22:55:46 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-12-29 22:55:46 [scrapy.middleware] INFO: Enabled item pipelines:
['myscrapy.pipelines.MyscrapyPipeline']
2019-12-29 22:55:46 [scrapy.core.engine] INFO: Spider opened
2019-12-29 22:55:46 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-12-29 22:55:46 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-12-29 22:55:46 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
2019-12-29 22:55:46 [scrapy.core.scraper] ERROR: Spider error processing <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
Traceback (most recent call last):
  File "d:\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\Workspace\WorkspaceForPython\SrcapyProject\myscrapy\myscrapy\spiders\sipder1.py", line 35, in parse
    item['nnn'] = 'nnn'
  File "d:\python\python37\lib\site-packages\scrapy\item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'MyscrapyItem does not support field: nnn'
2019-12-29 22:55:46 [scrapy.core.engine] INFO: Closing spider (finished)
2019-12-29 22:55:46 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 282,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7932,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.4607,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 12, 29, 14, 55, 46, 756770),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2019, 12, 29, 14, 55, 46, 296070)}
2019-12-29 22:55:46 [scrapy.core.engine] INFO: Spider closed (finished)
2019-12-29 22:58:16 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: myscrapy)
2019-12-29 22:58:16 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2019-12-29 22:58:16 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'myscrapy', 'LOG_FILE': './log.log', 'NEWSPIDER_MODULE': 'myscrapy.spiders', 'SPIDER_MODULES': ['myscrapy.spiders']}
2019-12-29 22:58:16 [scrapy.extensions.telnet] INFO: Telnet Password: af137e465a83ccd9
2019-12-29 22:58:16 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-12-29 22:58:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-12-29 22:58:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-12-29 22:58:16 [scrapy.middleware] INFO: Enabled item pipelines:
['myscrapy.pipelines.MyscrapyPipeline']
2019-12-29 22:58:16 [scrapy.core.engine] INFO: Spider opened
2019-12-29 22:58:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-12-29 22:58:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-12-29 22:58:17 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
2019-12-29 22:58:17 [scrapy.core.scraper] ERROR: Spider error processing <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
Traceback (most recent call last):
  File "d:\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\Workspace\WorkspaceForPython\SrcapyProject\myscrapy\myscrapy\spiders\sipder1.py", line 35, in parse
    item['nnn'] = 'nnn'
  File "d:\python\python37\lib\site-packages\scrapy\item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'MyscrapyItem does not support field: nnn'
2019-12-29 22:58:17 [scrapy.core.engine] INFO: Closing spider (finished)
2019-12-29 22:58:17 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 282,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7932,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.784828,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 12, 29, 14, 58, 17, 517604),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2019, 12, 29, 14, 58, 16, 732776)}
2019-12-29 22:58:17 [scrapy.core.engine] INFO: Spider closed (finished)
2019-12-29 22:59:33 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: myscrapy)
2019-12-29 22:59:33 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2019-12-29 22:59:33 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'myscrapy', 'LOG_FILE': './log.log', 'NEWSPIDER_MODULE': 'myscrapy.spiders', 'SPIDER_MODULES': ['myscrapy.spiders']}
2019-12-29 22:59:33 [scrapy.extensions.telnet] INFO: Telnet Password: e8f0f6edb5373d79
2019-12-29 22:59:33 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-12-29 22:59:33 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-12-29 22:59:33 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-12-29 22:59:33 [scrapy.middleware] INFO: Enabled item pipelines:
['myscrapy.pipelines.MyscrapyPipeline']
2019-12-29 22:59:33 [scrapy.core.engine] INFO: Spider opened
2019-12-29 22:59:33 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-12-29 22:59:33 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-12-29 22:59:33 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
2019-12-29 22:59:33 [scrapy.core.scraper] ERROR: Spider error processing <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
Traceback (most recent call last):
  File "d:\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\Workspace\WorkspaceForPython\SrcapyProject\myscrapy\myscrapy\spiders\sipder1.py", line 36, in parse
    item['nnn'] = 'nnn'
  File "d:\python\python37\lib\site-packages\scrapy\item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'MyscrapyItem does not support field: nnn'
2019-12-29 22:59:33 [scrapy.core.engine] INFO: Closing spider (finished)
2019-12-29 22:59:33 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 282,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7932,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.370314,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 12, 29, 14, 59, 33, 815504),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2019, 12, 29, 14, 59, 33, 445190)}
2019-12-29 22:59:33 [scrapy.core.engine] INFO: Spider closed (finished)
2019-12-29 23:00:15 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: myscrapy)
2019-12-29 23:00:15 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2019-12-29 23:00:15 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'myscrapy', 'LOG_FILE': './log.log', 'NEWSPIDER_MODULE': 'myscrapy.spiders', 'SPIDER_MODULES': ['myscrapy.spiders']}
2019-12-29 23:00:15 [scrapy.extensions.telnet] INFO: Telnet Password: b7c64292fbb3ba9f
2019-12-29 23:00:15 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-12-29 23:00:16 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-12-29 23:00:16 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-12-29 23:00:16 [scrapy.middleware] INFO: Enabled item pipelines:
['myscrapy.pipelines.MyscrapyPipeline']
2019-12-29 23:00:16 [scrapy.core.engine] INFO: Spider opened
2019-12-29 23:00:16 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-12-29 23:00:16 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-12-29 23:00:16 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
2019-12-29 23:00:16 [scrapy.core.scraper] ERROR: Spider error processing <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
Traceback (most recent call last):
  File "d:\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\Workspace\WorkspaceForPython\SrcapyProject\myscrapy\myscrapy\spiders\sipder1.py", line 37, in parse
    item['nnn'] = 'nnn'
  File "d:\python\python37\lib\site-packages\scrapy\item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'MyscrapyItem does not support field: nnn'
2019-12-29 23:00:16 [scrapy.core.engine] INFO: Closing spider (finished)
2019-12-29 23:00:16 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 282,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7932,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.825566,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 12, 29, 15, 0, 16, 857591),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2019, 12, 29, 15, 0, 16, 32025)}
2019-12-29 23:00:16 [scrapy.core.engine] INFO: Spider closed (finished)
2019-12-29 23:00:48 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: myscrapy)
2019-12-29 23:00:48 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2019-12-29 23:00:48 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'myscrapy', 'LOG_FILE': './log.log', 'NEWSPIDER_MODULE': 'myscrapy.spiders', 'SPIDER_MODULES': ['myscrapy.spiders']}
2019-12-29 23:00:48 [scrapy.extensions.telnet] INFO: Telnet Password: 199871154daaa691
2019-12-29 23:00:48 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-12-29 23:00:49 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-12-29 23:00:49 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-12-29 23:00:49 [scrapy.middleware] INFO: Enabled item pipelines:
['myscrapy.pipelines.MyscrapyPipeline']
2019-12-29 23:00:49 [scrapy.core.engine] INFO: Spider opened
2019-12-29 23:00:49 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-12-29 23:00:49 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-12-29 23:00:49 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
2019-12-29 23:00:49 [scrapy.core.scraper] ERROR: Spider error processing <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
Traceback (most recent call last):
  File "d:\python\python37\lib\site-packages\scrapy\utils\defer.py", line 102, in iter_errback
    yield next(it)
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\offsite.py", line 29, in process_spider_output
    for x in result:
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\referer.py", line 339, in <genexpr>
    return (_set_referer(r) for r in result or ())
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\urllength.py", line 37, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "d:\python\python37\lib\site-packages\scrapy\core\spidermw.py", line 84, in evaluate_iterable
    for r in iterable:
  File "d:\python\python37\lib\site-packages\scrapy\spidermiddlewares\depth.py", line 58, in <genexpr>
    return (r for r in result or () if _filter(r))
  File "E:\Workspace\WorkspaceForPython\SrcapyProject\myscrapy\myscrapy\spiders\sipder1.py", line 37, in parse
    item['nnn'] = 'nnn'
  File "d:\python\python37\lib\site-packages\scrapy\item.py", line 98, in __setitem__
    (self.__class__.__name__, key))
KeyError: 'MyscrapyItem does not support field: nnn'
2019-12-29 23:00:49 [scrapy.core.engine] INFO: Closing spider (finished)
2019-12-29 23:00:49 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 282,
 'downloader/request_count': 1,
 'downloader/request_method_count/GET': 1,
 'downloader/response_bytes': 7932,
 'downloader/response_count': 1,
 'downloader/response_status_count/200': 1,
 'elapsed_time_seconds': 0.70022,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 12, 29, 15, 0, 49, 732719),
 'log_count/DEBUG': 1,
 'log_count/ERROR': 1,
 'log_count/INFO': 10,
 'response_received_count': 1,
 'scheduler/dequeued': 1,
 'scheduler/dequeued/memory': 1,
 'scheduler/enqueued': 1,
 'scheduler/enqueued/memory': 1,
 'spider_exceptions/KeyError': 1,
 'start_time': datetime.datetime(2019, 12, 29, 15, 0, 49, 32499)}
2019-12-29 23:00:49 [scrapy.core.engine] INFO: Spider closed (finished)
2019-12-29 23:00:56 [scrapy.utils.log] INFO: Scrapy 1.8.0 started (bot: myscrapy)
2019-12-29 23:00:56 [scrapy.utils.log] INFO: Versions: lxml 4.4.2.0, libxml2 2.9.5, cssselect 1.1.0, parsel 1.5.2, w3lib 1.21.0, Twisted 19.10.0, Python 3.7.4 (tags/v3.7.4:e09359112e, Jul  8 2019, 20:34:20) [MSC v.1916 64 bit (AMD64)], pyOpenSSL 19.1.0 (OpenSSL 1.1.1d  10 Sep 2019), cryptography 2.8, Platform Windows-10-10.0.18362-SP0
2019-12-29 23:00:56 [scrapy.crawler] INFO: Overridden settings: {'BOT_NAME': 'myscrapy', 'LOG_FILE': './log.log', 'NEWSPIDER_MODULE': 'myscrapy.spiders', 'SPIDER_MODULES': ['myscrapy.spiders']}
2019-12-29 23:00:56 [scrapy.extensions.telnet] INFO: Telnet Password: 8ee1b5644e5f0ce4
2019-12-29 23:00:56 [scrapy.middleware] INFO: Enabled extensions:
['scrapy.extensions.corestats.CoreStats',
 'scrapy.extensions.telnet.TelnetConsole',
 'scrapy.extensions.logstats.LogStats']
2019-12-29 23:00:56 [scrapy.middleware] INFO: Enabled downloader middlewares:
['scrapy.downloadermiddlewares.httpauth.HttpAuthMiddleware',
 'scrapy.downloadermiddlewares.downloadtimeout.DownloadTimeoutMiddleware',
 'scrapy.downloadermiddlewares.defaultheaders.DefaultHeadersMiddleware',
 'scrapy.downloadermiddlewares.useragent.UserAgentMiddleware',
 'scrapy.downloadermiddlewares.retry.RetryMiddleware',
 'scrapy.downloadermiddlewares.redirect.MetaRefreshMiddleware',
 'scrapy.downloadermiddlewares.httpcompression.HttpCompressionMiddleware',
 'scrapy.downloadermiddlewares.redirect.RedirectMiddleware',
 'scrapy.downloadermiddlewares.cookies.CookiesMiddleware',
 'scrapy.downloadermiddlewares.httpproxy.HttpProxyMiddleware',
 'scrapy.downloadermiddlewares.stats.DownloaderStats']
2019-12-29 23:00:56 [scrapy.middleware] INFO: Enabled spider middlewares:
['scrapy.spidermiddlewares.httperror.HttpErrorMiddleware',
 'scrapy.spidermiddlewares.offsite.OffsiteMiddleware',
 'scrapy.spidermiddlewares.referer.RefererMiddleware',
 'scrapy.spidermiddlewares.urllength.UrlLengthMiddleware',
 'scrapy.spidermiddlewares.depth.DepthMiddleware']
2019-12-29 23:00:56 [scrapy.middleware] INFO: Enabled item pipelines:
['myscrapy.pipelines.MyscrapyPipeline']
2019-12-29 23:00:56 [scrapy.core.engine] INFO: Spider opened
2019-12-29 23:00:57 [scrapy.extensions.logstats] INFO: Crawled 0 pages (at 0 pages/min), scraped 0 items (at 0 items/min)
2019-12-29 23:00:57 [scrapy.extensions.telnet] INFO: Telnet console listening on 127.0.0.1:6023
2019-12-29 23:00:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100> (referer: None)
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['13', '19', '28', '30', '33', '2', '12'], 'qishu': '19090 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['4', '13', '20', '26', '28', '3', '12'], 'qishu': '19091 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['2', '11', '15', '27', '30', '2', '5'], 'qishu': '19092 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['16', '17', '26', '29', '35', '1', '7'], 'qishu': '19093 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['1', '12', '14', '26', '27', '7', '9'], 'qishu': '19094 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['3', '12', '17', '19', '31', '2', '6'], 'qishu': '19095 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['2', '12', '22', '23', '27', '2', '6'], 'qishu': '19096 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['10', '17', '20', '30', '35', '10', '12'], 'qishu': '19097 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['13', '15', '17', '19', '22', '3', '4'], 'qishu': '19098 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['4', '6', '18', '27', '33', '7', '9'], 'qishu': '19099 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100>
{'num': ['5', '8', '12', '19', '21', '6', '11'], 'qishu': '19100 '}
2019-12-29 23:00:57 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111> (referer: http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19090&to=19100)
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['5', '11', '18', '19', '27', '5', '6'], 'qishu': '19101 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['5', '10', '15', '19', '31', '3', '6'], 'qishu': '19102 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['5', '12', '22', '27', '32', '4', '7'], 'qishu': '19103 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['2', '7', '19', '22', '28', '3', '5'], 'qishu': '19104 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['1', '4', '9', '14', '17', '1', '6'], 'qishu': '19105 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['5', '8', '10', '32', '35', '2', '10'], 'qishu': '19106 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['5', '9', '19', '27', '35', '2', '3'], 'qishu': '19107 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['24', '27', '28', '31', '34', '4', '8'], 'qishu': '19108 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['2', '7', '8', '20', '25', '11', '12'], 'qishu': '19109 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['1', '19', '23', '24', '30', '4', '5'], 'qishu': '19110 '}
2019-12-29 23:00:57 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111>
{'num': ['6', '15', '20', '23', '27', '8', '10'], 'qishu': '19111 '}
2019-12-29 23:00:59 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122> (referer: http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19101&to=19111)
2019-12-29 23:00:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['3', '10', '16', '21', '33', '5', '6'], 'qishu': '19112 '}
2019-12-29 23:00:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['3', '11', '27', '34', '35', '1', '2'], 'qishu': '19113 '}
2019-12-29 23:00:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['3', '5', '7', '20', '23', '4', '11'], 'qishu': '19114 '}
2019-12-29 23:00:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['1', '18', '21', '28', '32', '5', '12'], 'qishu': '19115 '}
2019-12-29 23:00:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['2', '10', '16', '21', '23', '2', '12'], 'qishu': '19116 '}
2019-12-29 23:00:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['1', '18', '21', '25', '35', '7', '8'], 'qishu': '19117 '}
2019-12-29 23:00:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['2', '3', '13', '19', '26', '2', '3'], 'qishu': '19118 '}
2019-12-29 23:00:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['3', '6', '9', '23', '34', '2', '11'], 'qishu': '19119 '}
2019-12-29 23:00:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['6', '15', '17', '22', '25', '1', '9'], 'qishu': '19120 '}
2019-12-29 23:00:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['1', '2', '3', '7', '17', '4', '10'], 'qishu': '19121 '}
2019-12-29 23:00:59 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122>
{'num': ['5', '19', '25', '31', '33', '10', '11'], 'qishu': '19122 '}
2019-12-29 23:01:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133> (referer: http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19112&to=19122)
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['3', '13', '15', '26', '30', '5', '12'], 'qishu': '19123 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['7', '17', '26', '27', '30', '6', '12'], 'qishu': '19124 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['5', '8', '9', '14', '34', '2', '5'], 'qishu': '19125 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['5', '9', '16', '18', '30', '4', '7'], 'qishu': '19126 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['4', '7', '8', '11', '16', '9', '11'], 'qishu': '19127 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['20', '21', '25', '34', '35', '3', '12'], 'qishu': '19128 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['10', '13', '18', '23', '30', '6', '12'], 'qishu': '19129 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['1', '13', '20', '21', '26', '4', '10'], 'qishu': '19130 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['5', '6', '14', '27', '29', '6', '10'], 'qishu': '19131 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['3', '5', '6', '13', '18', '10', '12'], 'qishu': '19132 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133>
{'num': ['3', '12', '24', '27', '34', '1', '12'], 'qishu': '19133 '}
2019-12-29 23:01:00 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144> (referer: http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19123&to=19133)
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['5', '6', '7', '14', '17', '10', '11'], 'qishu': '19134 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['4', '5', '19', '25', '26', '1', '11'], 'qishu': '19135 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['3', '16', '20', '26', '29', '3', '9'], 'qishu': '19136 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['3', '5', '12', '13', '26', '7', '12'], 'qishu': '19137 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['4', '6', '7', '20', '29', '2', '4'], 'qishu': '19138 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['1', '5', '7', '8', '11', '6', '10'], 'qishu': '19139 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['3', '7', '8', '25', '27', '3', '5'], 'qishu': '19140 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['2', '10', '20', '21', '35', '1', '12'], 'qishu': '19141 '}
2019-12-29 23:01:00 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['3', '4', '26', '29', '33', '6', '7'], 'qishu': '19142 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['4', '22', '23', '24', '32', '6', '12'], 'qishu': '19143 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144>
{'num': ['2', '5', '20', '28', '31', '2', '11'], 'qishu': '19144 '}
2019-12-29 23:01:01 [scrapy.core.engine] DEBUG: Crawled (200) <GET http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155> (referer: http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19134&to=19144)
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['6', '15', '17', '22', '25', '1', '9'], 'qishu': '19120 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['1', '2', '3', '7', '17', '4', '10'], 'qishu': '19121 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['5', '19', '25', '31', '33', '10', '11'], 'qishu': '19122 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['3', '13', '15', '26', '30', '5', '12'], 'qishu': '19123 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['7', '17', '26', '27', '30', '6', '12'], 'qishu': '19124 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['5', '8', '9', '14', '34', '2', '5'], 'qishu': '19125 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['5', '9', '16', '18', '30', '4', '7'], 'qishu': '19126 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['4', '7', '8', '11', '16', '9', '11'], 'qishu': '19127 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['20', '21', '25', '34', '35', '3', '12'], 'qishu': '19128 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['10', '13', '18', '23', '30', '6', '12'], 'qishu': '19129 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['1', '13', '20', '21', '26', '4', '10'], 'qishu': '19130 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['5', '6', '14', '27', '29', '6', '10'], 'qishu': '19131 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['3', '5', '6', '13', '18', '10', '12'], 'qishu': '19132 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['3', '12', '24', '27', '34', '1', '12'], 'qishu': '19133 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['5', '6', '7', '14', '17', '10', '11'], 'qishu': '19134 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['4', '5', '19', '25', '26', '1', '11'], 'qishu': '19135 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['3', '16', '20', '26', '29', '3', '9'], 'qishu': '19136 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['3', '5', '12', '13', '26', '7', '12'], 'qishu': '19137 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['4', '6', '7', '20', '29', '2', '4'], 'qishu': '19138 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['1', '5', '7', '8', '11', '6', '10'], 'qishu': '19139 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['3', '7', '8', '25', '27', '3', '5'], 'qishu': '19140 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['2', '10', '20', '21', '35', '1', '12'], 'qishu': '19141 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['3', '4', '26', '29', '33', '6', '7'], 'qishu': '19142 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['4', '22', '23', '24', '32', '6', '12'], 'qishu': '19143 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['2', '5', '20', '28', '31', '2', '11'], 'qishu': '19144 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['5', '9', '19', '22', '32', '3', '5'], 'qishu': '19145 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['10', '11', '26', '33', '34', '1', '6'], 'qishu': '19146 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['9', '12', '19', '22', '33', '7', '8'], 'qishu': '19147 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['3', '4', '7', '11', '30', '8', '9'], 'qishu': '19148 '}
2019-12-29 23:01:01 [scrapy.core.scraper] DEBUG: Scraped from <200 http://datachart.500.com/dlt/zoushi/newinc/jbzs_foreback.php?expect=all&from=19145&to=19155>
{'num': ['1', '2', '7', '33', '35', '6', '10'], 'qishu': '19149 '}
2019-12-29 23:01:01 [scrapy.core.engine] INFO: Closing spider (finished)
2019-12-29 23:01:01 [scrapy.statscollectors] INFO: Dumping Scrapy stats:
{'downloader/request_bytes': 2386,
 'downloader/request_count': 6,
 'downloader/request_method_count/GET': 6,
 'downloader/response_bytes': 50869,
 'downloader/response_count': 6,
 'downloader/response_status_count/200': 6,
 'elapsed_time_seconds': 4.819826,
 'finish_reason': 'finished',
 'finish_time': datetime.datetime(2019, 12, 29, 15, 1, 1, 821612),
 'item_scraped_count': 85,
 'log_count/DEBUG': 91,
 'log_count/INFO': 10,
 'request_depth_max': 5,
 'response_received_count': 6,
 'scheduler/dequeued': 6,
 'scheduler/dequeued/memory': 6,
 'scheduler/enqueued': 6,
 'scheduler/enqueued/memory': 6,
 'start_time': datetime.datetime(2019, 12, 29, 15, 0, 57, 1786)}
2019-12-29 23:01:01 [scrapy.core.engine] INFO: Spider closed (finished)
